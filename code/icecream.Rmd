---
title: "不同天气温度冰淇淋销量"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: flatly
    highlight: pygments
    code_download: true
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
---



```{r setup, include=FALSE}
options(digits = 3)
knitr::opts_chunk$set(
  cache = TRUE,
  echo = TRUE,
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  out.width = "100%",
  fig.align = "center",
  fig.asp = 0.618, 
  fig.width = 4,
  fig.show = "hold"
)
```




```{r libraries, message = FALSE, warning = FALSE}
library(tidyverse)
library(tidybayes)
library(bayesplot)
library(rstan)
library(loo)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```





# 数据 

```{r}
icecream <- data.frame(
  temp = c( 11.9, 14.2, 15.2, 16.4, 17.2, 18.1, 
         18.5, 19.4, 22.1, 22.6, 23.4, 25.1),
  units = c( 185L, 215L, 332L, 325L, 408L, 421L, 
          406L, 412L, 522L, 445L, 544L, 614L)
  )
```



```{r}
ggplot(icecream, aes(temp, units)) + 
  geom_point()
```


# 传统的方法

探索冰淇淋销量与天气温度，在R语言中使用`lm()`

```{r}
fit_lm <- lm(units ~ 1 + temp, data = icecream)
summary(fit_lm)
```



```{r}
confint(fit_lm, level = 0.95)
```


但是，我们不满意，不满意在于

- 模型的假设？
- 模型的参数？
- 模型的解释？





# 贝叶斯建模

## linear models

线性模型

$$
\begin{align}
y_n &\sim \operatorname{normal}(\mu_n, \,\, \sigma)\\
\mu_n &= \alpha + \beta x_n \\
\alpha  &\sim  \operatorname{normal}(0, 4) \\
\beta  &\sim  \operatorname{normal}(0, 4)\\
\sigma  &\sim \operatorname{half-Cauchy}(1)
\end{align}
$$


```{r, warning=FALSE, message=FALSE}
stan_program <- "
data {
  int N;
  int<lower=0> y[N];
  vector[N] x;
}
parameters {
  real alpha;
  real beta;
  real<lower=0> sigma;
}
model {

  for(i in 1:N) {
    target += normal_lpdf(y[i] | alpha + beta * x[i], sigma);
  }
  alpha  ~ normal(0, 10);
  beta   ~ normal(0, 10);
  sigma  ~ exponential(1);
}
generated quantities {
  vector[N] y_rep;
  vector[N] log_lik;
  for (n in 1:N) {
    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);
    log_lik[n] = normal_lpdf(y[n] | alpha + beta * x[n], sigma);
  }
}
"

stan_data <- icecream %>%
  tidybayes::compose_data(
   N = nrow(.),
   x = temp, 
   y = units
  )


fit_normal <- stan(model_code = stan_program, data = stan_data)
```




```{r}
summary(fit_normal)[["summary"]][c("alpha", "beta", "sigma"), ]
```




```{r}
fit_normal %>% 
  bayesplot::mcmc_hist(pars = c("alpha", "beta", "sigma"))
```



```{r, eval = FALSE}
fit_normal %>% 
  tidybayes::gather_draws(alpha, beta, sigma) %>% 
  ggplot(aes(x = .value)) +
  geom_density(alpha = 0.3, fill = "gray50") +
  facet_wrap(vars(.variable), scales = "free") +
  labs(x = NULL, y = NULL)
```



```{r}
y_rep <- as.matrix(fit_normal, pars = "y_rep")
bayesplot::ppc_dens_overlay(y = stan_data$units, yrep = y_rep[1:200, ])
```



```{r}
y_rep <- as.matrix(fit_normal, pars = "y_rep")
bayesplot::ppc_intervals(y = stan_data$units, 
                         yrep = y_rep, 
                         x = stan_data$temp
                         ) 
```


```{r}
fit_normal %>% 
  tidybayes::gather_draws(y_rep[i]) %>% 
  mean_qi() %>% 
  bind_cols(icecream) %>% 
  
  ggplot(aes(temp, units)) + 
  geom_point(size = 5) +
  geom_line(aes(y = .value), size = 2, color = "orange") +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.3, 
              fill = "gray50"
              ) +
  theme_classic()
```



## log normal models

有时候，我们对响应变量做log转化，

$$
\begin{align}
\log(y_n) &\sim \operatorname{normal}(\mu_n, \,\, \sigma)\\
\mu_n &= \alpha + \beta x_n 
\end{align}
$$
equivalent to


$$
\begin{align}
y_n &\sim \operatorname{Lognormal}(\mu_n, \,\, \sigma)\\
\mu_n &= \alpha + \beta x_n 
\end{align}
$$


```{r, warning=FALSE, message=FALSE}
stan_program <- "
data {
  int N;
  int<lower=0> y[N];
  vector[N] x;
}
parameters {
  real alpha;
  real beta;
  real<lower=0> sigma;
}
model {

  for(i in 1:N) {
    target += lognormal_lpdf(y[i] | alpha + beta * x[i], sigma);
  }
  alpha  ~ normal(0, 10);
  beta   ~ normal(0, 10);
  sigma  ~ exponential(1);
}
generated quantities {
  vector[N] y_rep;
  vector[N] log_lik;
  for (n in 1:N) {
    y_rep[n] = lognormal_rng(alpha + beta * x[n], sigma);
    log_lik[n] = lognormal_lpdf(y[n] | alpha + beta * x[n], sigma);
  }
}
"

stan_data <- icecream %>%
  tidybayes::compose_data(
   N = nrow(.),
   x = temp, 
   y = units
  )


fit_lognormal <- stan(model_code = stan_program, data = stan_data)
```



```{r}
summary(fit_lognormal)[["summary"]][c("alpha", "beta", "sigma"), ]
```



```{r}
fit_lognormal %>% 
  bayesplot::mcmc_hist(pars = c("alpha", "beta", "sigma"))
```




```{r}
y_rep <- as.matrix(fit_lognormal, pars = "y_rep")
bayesplot::ppc_dens_overlay(y = stan_data$units, yrep = y_rep[1:200, ])
```



```{r}
y_rep <- as.matrix(fit_lognormal, pars = "y_rep")
bayesplot::ppc_intervals(y = stan_data$units, 
                         yrep = y_rep, 
                         x = stan_data$temp
                         ) 
```


```{r}
fit_lognormal %>% 
  tidybayes::gather_draws(y_rep[i]) %>% 
  mean_qi() %>% 
  bind_cols(icecream) %>% 
  
  ggplot(aes(temp, units)) + 
  geom_point(size = 5) +
  geom_line(aes(y = .value), size = 2, color = "orange") +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.3, 
              fill = "gray50"
              ) +
  theme_classic()
```




## Poisson Models

冰激凌销量，是一种**计数类型**的变量，因此可以用泊松回归分析

$$
\begin{align}
y_n &\sim \operatorname{Poisson}(\lambda_n)\\
\log(\lambda_n) &= \alpha + \beta x_n 
\end{align}
$$


```{r, warning=FALSE, message=FALSE}
stan_program <- "
functions {
  /*
  * Alternative to poisson_log_rng() that 
  * avoids potential numerical problems during warmup
  */
  int poisson_log_safe_rng(real eta) {
    real pois_rate = exp(eta);
    if (pois_rate >= exp(20.79))
      return -9;
    return poisson_rng(pois_rate);
  }
}
data {
  int N;
  int<lower=0> y[N];
  vector[N] x;
}
parameters {
  real alpha;
  real beta;
}
model {

  for(i in 1:N) {
    target += poisson_log_lpmf(y[i] | alpha + beta * x[i]);
  }
  alpha  ~ normal(0, 10);
  beta   ~ normal(0, 10);
}
generated quantities {
  int y_rep[N];
  vector[N] log_lik;
  for (n in 1:N) {
    y_rep[n] = poisson_log_safe_rng(alpha + beta * x[n]);
    log_lik[n] = poisson_log_lpmf(y[n] | alpha + beta * x[n]);
  }
}
"

stan_data <- icecream %>%
  tidybayes::compose_data(
   N = nrow(.),
   x = temp, 
   y = units
  )


fit_poisson <- stan(model_code = stan_program, data = stan_data)
```



```{r}
rstan::traceplot(fit_poisson)
```



```{r}
summary(fit_poisson)[["summary"]][c("alpha", "beta"), ]
```




```{r}
fit_poisson %>% 
  bayesplot::mcmc_hist(pars = c("alpha", "beta"))
```




```{r}
y_rep <- as.matrix(fit_poisson, pars = "y_rep")
bayesplot::ppc_dens_overlay(y = stan_data$units, yrep = y_rep[1:200, ])
```



```{r}
y_rep <- as.matrix(fit_poisson, pars = "y_rep")
bayesplot::ppc_intervals(y = stan_data$units, 
                         yrep = y_rep, 
                         x = stan_data$temp
                         ) 
```


```{r}
fit_poisson %>% 
  tidybayes::gather_draws(y_rep[i]) %>% 
  mean_qi() %>% 
  bind_cols(icecream) %>% 
  
  ggplot(aes(temp, units)) + 
  geom_point(size = 5) +
  geom_line(aes(y = .value), size = 2, color = "orange") +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.3, 
              fill = "gray50"
              ) +
  theme_classic()
```




## binomal models

泊松分布可看成是二项分布的极限，因此可以使用更灵活的二项式回归模型

$$
\begin{align}
y_n &\sim \mathcal{binomial}(N, \theta_n)\\
\text{logit}(\theta_n) &= log\Big(\frac{\theta_{n}}{1 - \theta_{n}}\Big) =\alpha + \beta x_n \\
\text{equivalent to,} \quad \theta_n &= \frac{1}{1 + \exp[- (\alpha + \beta x_n)]} \\
& = \frac{\exp(\alpha + \beta x_n)}{1 + \exp (\alpha + \beta x_n)} \\
\end{align}
$$

```{r, warning=FALSE, message=FALSE}
stan_program <- "
data {
  int<lower=1> N;
  int<lower=1> trials;
  vector[N] x;
  int y[N];
  real new_x;
}
parameters {
  real alpha;
  real beta;
}
transformed parameters {
  vector[N] theta;
  for (i in 1:N) {
    theta[i] = alpha + beta * x[i];
  }
}
model {
  for (i in 1:N) {
    target += binomial_logit_lpmf(y[i] | trials, theta[i]);
  }
  
  target += cauchy_lpdf(alpha | 0, 5);
  target += normal_lpdf(beta | 0, 5);
} 
generated quantities {
  vector[N] log_lik;
  int y_rep[N];
  int y_predict;

  for(n in 1:N) {
    log_lik[n] = binomial_logit_lpmf(y[n] | trials, theta[n]);
  }
  
  for (n in 1:N) {
     y_rep[n] = binomial_rng(trials, inv_logit(theta[n]));
  }
   //predict unit for temp = 35

   y_predict = binomial_rng(trials, inv_logit(alpha + beta * new_x));
}
"


stan_data <- icecream %>%
  tidybayes::compose_data(
   N = nrow(.),
   x = temp, 
   y = units, 
   trials = 800,
   new_x = 35
  )

fit_binomial <- stan(model_code = stan_program, data = stan_data)
```




```{r, echo=FALSE}
summary(fit_binomial)[["summary"]][c("alpha", "beta"), ]
```




```{r}
fit_binomial %>% 
  bayesplot::mcmc_hist(pars = c("alpha", "beta"))
```





```{r}
y_rep <- as.matrix(fit_binomial, pars = "y_rep")
bayesplot::ppc_dens_overlay(y = stan_data$units, yrep = y_rep[1:200, ])
```



```{r}
bayesplot::ppc_intervals(y = stan_data$units, 
                         yrep = y_rep, 
                         x = stan_data$temp
                         ) 
```




```{r}
fit_binomial %>% 
  tidybayes::gather_draws(y_rep[i]) %>% 
  mean_qi() %>% 
  bind_cols(icecream) %>% 
  
  ggplot(aes(temp, units)) + 
  geom_point(size = 5) +
  geom_line(aes(y = .value), size = 2, color = "orange") +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.3, 
              fill = "gray50"
              ) +
  theme_classic()
```

# 模型比较

## LOO-CV
我们可以用loo宏包（stan开发组开发的）[比较模型](http://mc-stan.org/loo/articles/loo2-with-rstan.html)

- elpd_loo (expected log predictive density), 
- p_loo  (effective number of parameters),
- looic = −2elpd_loo (the LOO information criterion).

```{r}
loo_normal <- loo::loo(loo::extract_log_lik(fit_normal))
loo_normal
```

```{r}
loo_lognormal <- loo::loo(loo::extract_log_lik(fit_lognormal))
loo_lognormal
```

```{r}
loo_poisson <- loo::loo(loo::extract_log_lik(fit_poisson))
loo_poisson
```

```{r}
loo_binomial <- loo::loo(loo::extract_log_lik(fit_binomial))
loo_binomial
```


```{r}
loo::compare(loo_normal, loo_lognormal, loo_poisson, loo_binomial)
```

结果显示：

- 第二个模型`lognormal`相对最优
- 第1列显示的是，每个模型的elpd与模型中最大的elpd值的差
- 这个负数，代表该模型比最优秀的模型，预测能力差了多少





# 应用

在气温35度的时候，我们库存多少冰激凌，才能实现利润最大化？


- 气温35度的时候，贝叶斯模型预测的销量值
```{r}
y_predict <- fit_binomial %>% 
  tidybayes::spread_draws(y_predict) %>% 
  pull(y_predict)
y_predict
```


- 定义效能函数

```{r}
utility_fun <- function(sales_predict, bought, temp) {
  tibble(
    bought  = bought, 
    utility = -100 - 1 * bought + 2 * pmin(sales_predict, bought)
  )
}
```


- 假定库存从700到800，我们得到相应的利润曲线 
```{r}
bought <- 700:800
df <- bought %>%
  map_df(
    ~utility_fun(sales_predict = y_predict, bought = ., temp = 35)
    ) %>% 
  group_by(bought) %>% 
  summarise(
    utility = mean(utility)
  )
  

df %>%
  ggplot(aes(bought, utility)) +
  geom_smooth(stat = "identity") 
```



